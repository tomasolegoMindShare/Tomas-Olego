{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a1436-0b29-4480-93d5-3163aa7c23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Imports, Environment Setup & MLflow Autolog\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "def cast_to_float64(X):\n",
    "    \"\"\"Cast any array or DataFrame of numerics to float64.\"\"\"\n",
    "    return X.astype(np.float64)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths from environment variables (cannot change existing env vars)\n",
    "DATA_PATH     = Path(\"/mnt/data\") / os.environ.get(\"DOMINO_PROJECT_NAME\", \"\") / \"WineQualityData.csv\"\n",
    "ARTIFACTS_DIR = Path(\"/mnt/artifacts\")\n",
    "MODEL_DIR     = Path(\"/mnt/code/models\")\n",
    "\n",
    "logger.info(f\"Data path set to: {DATA_PATH}\")\n",
    "assert DATA_PATH.exists(), f\"Data file not found at {DATA_PATH}\"\n",
    "\n",
    "# Configure MLflow experiment & autolog (no model logging to avoid duplicates)\n",
    "mlflow.set_experiment(\n",
    "    experiment_name=(\n",
    "        f\"{os.environ.get('DOMINO_PROJECT_NAME','')} \"\n",
    "        f\"{os.environ.get('DOMINO_STARTING_USERNAME','')} \"\n",
    "        f\"{os.environ.get('MLFLOW_NAME','')}\"\n",
    "    )\n",
    ")\n",
    "mlflow.sklearn.autolog(log_models=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b24449-e494-4483-86a1-0a9c1352042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Load Data & Initial Inspection\n",
    "from IPython.display import display\n",
    "\n",
    "logger.info(f\"Reading data from {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "logger.info(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "display(df.head())\n",
    "df.info()\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13baf4a-df78-4921-b602-00f6b12315f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Preprocessing & Feature Selection\n",
    "# 1️⃣ Clean & standardize column names\n",
    "logger.info(\"Cleaning column names...\")\n",
    "df.columns = [col.strip().replace(' ', '_').lower() for col in df.columns]\n",
    "\n",
    "# 2️⃣ Create binary “is_red” feature\n",
    "logger.info(\"Creating 'is_red' feature...\")\n",
    "df['is_red'] = (df['type'] == 'red').astype(int)\n",
    "\n",
    "# 3️⃣ Drop any rows with missing values\n",
    "logger.info(\"Dropping missing values...\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 4️⃣ Compute Pearson correlations on numeric columns\n",
    "target = 'quality'\n",
    "corrs = df.corr(numeric_only=True)[target].drop(target)\n",
    "\n",
    "# 5️⃣ Select features with |corr| > 0.08, sorted by absolute correlation\n",
    "important_feats = (\n",
    "    corrs\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    "    .loc[lambda s: s > 0.08]\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "logger.info(f\"Selected features based on |corr|>0.08: {important_feats}\")\n",
    "\n",
    "# 6️⃣ Define feature matrix X and target vector y\n",
    "X = df[important_feats]\n",
    "y = df[target].astype(float)\n",
    "\n",
    "# 7️⃣ Quick inspection\n",
    "display(X.head())\n",
    "logger.info(\"Feature selection complete. X.shape=%s, y.shape=%s\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ae3f3-2948-407c-b3d7-eb873a3b97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Build Preprocessing & Modeling Pipeline\n",
    "\n",
    "# 1️⃣ No-op transformer for casting inputs to float64\n",
    "cast_to_float = FunctionTransformer(cast_to_float64, validate=False)\n",
    "\n",
    "# 2️⃣ Numeric features selected in Cell 3\n",
    "numeric_features = important_feats\n",
    "\n",
    "# 3️⃣ Preprocessing: scale numeric features\n",
    "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('num', numeric_transformer, numeric_features)],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 4️⃣ Model with early stopping to speed up training and guard against overfitting\n",
    "model = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10\n",
    ")\n",
    "\n",
    "# 5️⃣ Assemble the full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('cast_to_float', cast_to_float),\n",
    "    ('preprocessor',   preprocessor),\n",
    "    ('regressor',      model)\n",
    "])\n",
    "\n",
    "logger.info(\"Pipeline created successfully\")\n",
    "logger.info(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15ec97-8a66-497f-b021-450b6e13a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Train/Test Split, Training, MLflow Logging & PyFunc Wrapping\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "import joblib\n",
    "\n",
    "# 1️⃣ Split the data\n",
    "test_size    = float(os.environ.get('TEST_SIZE',    0.3))\n",
    "random_state = int(os.environ.get('RANDOM_STATE',  42))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "# 2️⃣ Define the CastAndPredict wrapper (picklable top‐level class)\n",
    "class CastAndPredictModel(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # load the sklearn pipeline you just logged earlier in this run\n",
    "        self.pipeline = mlflow.sklearn.load_model(context.artifacts[\"sk_model\"])\n",
    "    def predict(self, context, model_input):\n",
    "        # cast all incoming columns to float64 so MLflow schema check passes\n",
    "        return self.pipeline.predict(model_input.astype(\"float64\"))\n",
    "\n",
    "# 3️⃣ Start the one MLflow run (autolog already set up in Cell 1)\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.set_tag(\"Model_Type\", \"sklearn_histgb\")\n",
    "\n",
    "    # — train & eval as before —\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    r2   = r2_score(y_test, preds)\n",
    "    mse  = mean_squared_error(y_test, preds)\n",
    "    mlflow.log_metrics({\"r2_score\": r2, \"mean_squared_error\": mse})\n",
    "\n",
    "    with open(ARTIFACTS_DIR / 'dominostats.json', 'w') as f:\n",
    "        json.dump({\"r2_score\": round(r2,3), \"mean_squared_error\": round(mse,3)}, f)\n",
    "\n",
    "    # — 4️⃣ Log the sklearn pipeline as before —\n",
    "    signature     = infer_signature(X_train, pipeline.predict(X_train))\n",
    "    input_example = X_train.head(5).astype(\"float64\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline,\n",
    "        artifact_path=\"histgb_pipeline_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"scikit-learn>=1.0.0\",\n",
    "            \"pandas>=1.0.0\",\n",
    "            \"cloudpickle>=2.0.0\",\n",
    "            \"mlflow>=2.0.0\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # — 5️⃣ **Now** log the PyFunc wrapper in the _same_ run —\n",
    "    sklearn_artifact_uri = f\"runs:/{run.info.run_id}/histgb_pipeline_model\"\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"wine_quality_pyfunc\",\n",
    "        python_model=CastAndPredictModel(),\n",
    "        artifacts={\"sk_model\": sklearn_artifact_uri},\n",
    "        signature=ModelSignature(\n",
    "            inputs=Schema([ColSpec(\"double\", name=f) for f in important_feats]),\n",
    "            outputs=Schema([ColSpec(\"double\")])\n",
    "        ),\n",
    "        # you can omit input_example here\n",
    "    )\n",
    "\n",
    "    # — 6️⃣ Register the PyFunc flavor in the registry (outside the run, if you like) —\n",
    "    pyfunc_uri = f\"runs:/{run.info.run_id}/wine_quality_pyfunc\"\n",
    "    model_name = os.environ.get(\"MLFLOW_MODEL_NAME\", \"WineQualityModel\")\n",
    "    mlflow.register_model(pyfunc_uri, model_name)\n",
    "\n",
    "# when this `with` block exits, MLflow will automatically end the run.\n",
    "logger.info(\"All artifacts logged and model registered in a single MLflow run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6b46a-75bb-4ee5-80d9-01aaf89fcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Serialize Final Model\n",
    "\n",
    "import joblib\n",
    "\n",
    "model_file = MODEL_DIR / 'histgb_pipeline_model.joblib'\n",
    "joblib.dump(pipeline, model_file)\n",
    "logger.info(f\"Model serialized to {model_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
